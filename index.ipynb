{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning and Pruning in Decision Trees - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you will use the titanic dataset to see the impact of tree pruning and hyperparameter tuning on the predictive performance of a decision tree classifier. Pruning reduces the size of decision trees by removing nodes of the tree that do not provide much predictive power to classify instances. Decision trees are the most susceptible out of all the machine learning algorithms to overfitting and effective pruning can reduce this likelihood. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lab you will: \n",
    "\n",
    "- Determine the optimal hyperparameters for a decision tree model and evaluate the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries\n",
    "\n",
    "Let's first import the libraries you'll need for this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data\n",
    "\n",
    "The titanic dataset, available in `'titanic.csv'`, is all cleaned up and preprocessed for you so that you can focus on pruning and optimization. Import the dataset and print the first five rows of the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId   Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  Pclass_3  \\\n",
       "0            1  22.0      1      0   7.2500         0         0         1   \n",
       "1            2  38.0      1      0  71.2833         1         0         0   \n",
       "2            3  26.0      0      0   7.9250         0         0         1   \n",
       "3            4  35.0      1      0  53.1000         1         0         0   \n",
       "4            5  35.0      0      0   8.0500         0         0         1   \n",
       "\n",
       "   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Survived  \n",
       "0           0         1           0           0           1         0  \n",
       "1           1         0           1           0           0         1  \n",
       "2           1         0           0           0           1         1  \n",
       "3           1         0           0           0           1         1  \n",
       "4           0         1           0           0           1         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv('titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>886</td>\n",
       "      <td>887</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>887</td>\n",
       "      <td>888</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>889</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>889</td>\n",
       "      <td>890</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>891</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId        Age  SibSp  Parch   Fare  Pclass_1  Pclass_2  \\\n",
       "886          887  27.000000      0      0  13.00         0         1   \n",
       "887          888  19.000000      0      0  30.00         1         0   \n",
       "888          889  29.699118      1      2  23.45         0         0   \n",
       "889          890  26.000000      0      0  30.00         1         0   \n",
       "890          891  32.000000      0      0   7.75         0         0   \n",
       "\n",
       "     Pclass_3  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \\\n",
       "886         0           0         1           0           0           1   \n",
       "887         0           1         0           0           0           1   \n",
       "888         1           1         0           0           0           1   \n",
       "889         0           0         1           1           0           0   \n",
       "890         1           0         1           0           1           0   \n",
       "\n",
       "     Survived  \n",
       "886         0  \n",
       "887         1  \n",
       "888         0  \n",
       "889         1  \n",
       "890         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and test sets\n",
    "\n",
    "- Assign the `'Survived'` column to `y` \n",
    "- Drop the `'Survived'` and `'PassengerId'` columns from `df`, and assign the resulting DataFrame to `X` \n",
    "- Split `X` and `y` into training and test sets. Assign 30% to the test set and set the `random_state` to `SEED` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y \n",
    "y = df['Survived']\n",
    "X = df.drop(columns = 'Survived')\n",
    "\n",
    "# Split into training and test sets\n",
    "SEED = 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a vanilla classifier\n",
    "\n",
    "__Note:__ The term \"vanilla\" is used for a machine learning algorithm with its default settings (no tweaking/tuning).\n",
    "\n",
    "- Instantiate a decision tree \n",
    "  - Use the `'entropy'` criterion and set the `random_state` to `SEED` \n",
    "- Fit this classifier to the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier using training data\n",
    "dt = DecisionTreeClassifier(random_state = SEED)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions \n",
    "- Create a set of predictions using the test set \n",
    "- Using `y_test` and `y_pred`, calculate the AUC (Area under the curve) to check the predictive performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.752031827223643"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions using test set \n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Check the AUC of predictions\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Tree Depth\n",
    "\n",
    "Let's first check for the best depth parameter for our decision tree: \n",
    "\n",
    "- Create an array for `max_depth` values ranging from 1 - 32  \n",
    "- In a loop, train the classifier for each depth value (32 runs) \n",
    "- Calculate the training and test AUC for each run \n",
    "- Plot a graph to show under/overfitting and the optimal value \n",
    "- Interpret the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1,) and (32,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c932f42e0323>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Train AUC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Test AUC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AUC score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2793\u001b[0m     return gca().plot(\n\u001b[1;32m   2794\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2795\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \"\"\"\n\u001b[1;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1666\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1667\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 270\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1,) and (32,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Identify the optimal tree depth for given data\n",
    "max_depths = np.linspace(1, 32, 32, endpoint = True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_depth in max_depths:\n",
    "    dt = DecisionTreeClassifier(criterion = 'entropy', max_depth = max_depth, random_state = SEED)\n",
    "    dt.fit(X_train, y_train)\n",
    "    train_pred = dt.predict(X_train)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    \n",
    "    train_results.append(roc_auc)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    \n",
    "    test_results.append(roc_auc)\n",
    "\n",
    "plt.figure(figsize = (12,6))\n",
    "plt.plot(max_depth, train_results, 'b', label = 'Train AUC')\n",
    "plt.plot(max_depth, test_results, 'r', label = 'Test AUC')\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('Three depth')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You observations here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum Sample Split\n",
    "\n",
    "Now check for the best `min_samples_splits` parameter for our decision tree \n",
    "\n",
    "- Create an array for `min_sample_splits` values ranging from 0.1 - 1 with an increment of 0.1 \n",
    "- In a loop, train the classifier for each `min_samples_splits` value (10 runs) \n",
    "- Calculate the training and test AUC for each run \n",
    "- Plot a graph to show under/overfitting and the optimal value \n",
    "- Interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the optimal min-samples-split for given data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your observations here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum Sample Leafs\n",
    "\n",
    "Now check for the best `min_samples_leafs` parameter value for our decision tree \n",
    "\n",
    "- Create an array for `min_samples_leafs` values ranging from 0.1 - 0.5 with an increment of 0.1 \n",
    "- In a loop, train the classifier for each `min_samples_leafs` value (5 runs) \n",
    "- Calculate the training and test AUC for each run \n",
    "- Plot a graph to show under/overfitting and the optimal value \n",
    "- Interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the optimal value for minimum sample leafs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your observations here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Features\n",
    "\n",
    "Now check for the best `max_features` parameter value for our decision tree \n",
    "\n",
    "- Create an array for `max_features` values ranging from 1 - 12 (1 feature vs all)\n",
    "- In a loop, train the classifier for each `max_features` value (12 runs) \n",
    "- Calculate the training and test AUC for each run \n",
    "- Plot a graph to show under/overfitting and the optimal value \n",
    "- Interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best value for optimal maximum feature size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your observations here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-train the classifier with chosen values\n",
    "\n",
    "Now we will use the best values from each training phase above and feed it back to our classifier. Then we can see if there is any improvement in predictive performance. \n",
    "\n",
    "- Train the classifier with the optimal values identified \n",
    "- Compare the AUC of the new model with the earlier vanilla decision tree AUC \n",
    "- Interpret the results of the comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a classifier with optimal values identified above\n",
    "dt = None\n",
    "\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = None\n",
    "roc_auc = None\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You observations here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we shall talk about hyperparameter tuning using a technique called \"grid-search\" to make this process even more granular and decisive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "In this lesson, we looked at tuning a decision tree classifier in order to avoid overfitting and increasing the generalization capabilities of the classifier. For the titanic dataset, we see that identifying optimal parameter values can result in some improvements towards predictions. This idea will be exploited further in upcoming lessons and labs. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
